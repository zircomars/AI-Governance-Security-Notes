# üî∑ Muita pohdintoja ja tulevaisuuden asioita

> T√§m√§ README.md kuvaa mahdollisia tulevaisuuden kehityskulkuja. Todenn√§k√∂isyyksi√§ on vaikea arvioida, koska teko√§lyn kanssa liittyy leikkimist√§, testaamista ja odottamattomia yll√§tyksi√§. On haastavaa ennustaa, mit√§ tapahtuu seuraavaksi.  
>  
> Teko√§lyn k√§ytt√∂√∂n liittyy aina riskej√§ ‚Äî virheit√§, haavoittuvuuksia ja odottamattomia tilanteita, joita ei voida t√§ysin poistaa. Siksi teko√§lyn kanssa toimiminen vaatii varovaisuutta, ymm√§rryst√§ ja jatkuvaa arviointia.
>  
> Haavoittuvuuksia syntyy varmasti, ja niit√§ voidaan hy√∂dynt√§√§ jopa **24 tunnin sis√§ll√§**. Lopputulos riippuu aina tekij√§st√§ ja osaamisesta. Koulutus ja ohjeistus vaikuttavat siihen, miten turvallisesti teko√§ly√§ k√§ytet√§√§n.  
>  
> Osa k√§ytt√§jist√§ on tarkkoja ja varovaisia, eiv√§tk√§ sy√∂t√§ salassa pidett√§vi√§ tietoja teko√§lyn chattiin. Toiset voivat vahingossa sy√∂tt√§√§ arkaluonteista tietoa. On vaikea ennustaa, mit√§ tapahtuu, jos teko√§lylle sy√∂tet√§√§n vahingossa tiettyj√§ tietoja ‚Äî voiko niit√§ saada takaisin, minne ne p√§√§tyv√§t ja miten niit√§ k√§sitell√§√§n.  
>  
> N√§ihin kysymyksiin ei ole yksiselitteisi√§ vastauksia, ja siksi teko√§lyn k√§ytt√∂ vaatii jatkuvaa arviointia, varovaisuutta ja ymm√§rryst√§ siit√§, miten dataa k√§sitell√§√§n ja mit√§ riskej√§ siihen liittyy.



# üî∑ AI-agenttien kehitys, EU AI Act ja tulevaisuuden riskit (2026‚Äì2028)

T√§m√§ osio kuvaa, miten AI-agentit, EU AI Act, Shadow AI ja organisaatioiden arkkitehtuurivastuut kehittyv√§t vuosina 2026‚Äì2028. Sis√§lt√∂ perustuu teknologian kehitykseen, s√§√§ntelyn etenemiseen ja agenttipohjaisten j√§rjestelmien yleistymiseen.

---

## üî∂ 1. Teko√§lyagentit ja assistentit: mit√§ on tulossa?

### Agenttien nopea arkip√§iv√§istyminen

- Agentit siirtyv√§t kirjoitetusta tuotannosta automaatioon: IT-operaatiot, tietoturva, asiakaspalvelu, dokumentaatio ja integraatiot.  
- Organisaatiot rakentavat agenttiputkia, joissa yksi agentti valvoo toista.  
- Konsultit ja integraatiopalvelut alkavat myyd√§ agenttipohjaisia palvelupaketteja, mik√§ lis√§√§ rajapintakriisej√§.

> Agenttien ja assistenttien toiminnasta ei voida aina ennustaa, mit√§ ne tekev√§t, ellei niiden toimintaa valvota aktiivisesti. Siksi jokaisen agentin taustalla t√§ytyy olla koulutettu ja ohjeistettu fyysinen ihminen, joka seuraa agentin toimintaa ja puuttuu siihen tarvittaessa. Jos agentti kohtaa poikkeavia tilanteita, esteit√§ tai odottamattomia yll√§tyksi√§, automaattinen toiminta ei saa jatkua ilman valvontaa. Ihmisen teht√§v√§n√§ on pys√§ytt√§√§ prosessi, arvioida tilanne ja jatkaa siit√§ eteenp√§in turvallisesti ja hallitusti.

### Agenttien autonomia kasvaa

- Oikeudet laajenevat: lukeminen ‚Üí kirjoittaminen ‚Üí muutosten tekeminen ‚Üí automaattiset p√§√§t√∂kset.  
- Agentit alkavat tehd√§ hallinnollisia p√§√§t√∂ksi√§, joita ei viel√§ osata t√§ysin valvoa.

### üî∂ Agentti vs. ihminen ty√∂ss√§: keskeiset erot

- Agentti suorittaa s√§√§nt√∂pohjaisia ja toistuvia teht√§vi√§, mutta ihminen tekee harkintaa, tulkintaa ja p√§√§t√∂ksi√§, joita ei voi automatisoida.

- Agentti toimii vain rajapintojen, skriptien ja k√§ytt√∂oikeuksien puitteissa, kun taas ihminen pystyy toimimaan my√∂s tilanteissa, joissa ohjeet ovat puutteellisia tai ep√§selvi√§.

- Agentti ei ymm√§rr√§ motivaatiota, tunnetiloja, vuorovaikutusta tai tiimidynamiikkaa. Ihminen pystyy arvioimaan n√§m√§ ja tekem√§√§n p√§√§t√∂ksi√§, jotka perustuvat kokonaiskuvaan.

- Agentti ei kanna vastuuta. Kaikki agentin tekem√§t toimet ovat aina ihmisen vastuulla, erityisesti EU AI Actin mukaan.

- Agentti ei kykene eettiseen arviointiin. Ihminen pystyy huomioimaan oikeudenmukaisuuden, syrjim√§tt√∂myyden ja tilanteen erityispiirteet.

- Agentti ei opi itsen√§isesti ilman dataa ja ohjausta. Ihminen pystyy oppimaan kokemuksesta, virheist√§ ja intuitiosta.

- Agentti ei voi k√§sitell√§ luottamuksellisia tai arkaluonteisia tilanteita, kuten konfliktien ratkaisua, palautekeskusteluja tai kriisitilanteita. N√§m√§ ovat aina ihmisen teht√§vi√§.

- Agentti ei ymm√§rr√§ kontekstia tai poikkeuksia. Ihminen pystyy tunnistamaan tilanteet, joissa s√§√§nt√∂j√§ t√§ytyy soveltaa joustavasti tai joissa automaatio t√§ytyy pys√§ytt√§√§.

- Agentti voi tukea rekrytointia teknisesti (suodatus, aikataulutus, dokumentointi), mutta ei voi valita ty√∂ntekij√§√§ tai arvioida potentiaalia. Ihminen tekee lopullisen arvion.

- Agentti voi suorittaa automaatiota, mutta ei voi rakentaa sit√§. Automaatio syntyy aina ihmisen suunnittelemasta logiikasta, skripteist√§ ja p√§√§t√∂ksist√§.

- Agentti ei kykene kantamaan vastuuta virheist√§ tai oikeudellisista seurauksista. Ihminen vastaa aina agentin toiminnasta, my√∂s silloin kun agentti toimii virheellisesti.

---

## üî∂ 2. EU AI Act: vaikutukset vuosina 2026‚Äì2027

### Aikataulu

- **2026:** EU AI Act tulee voimaan.  
- **2027:** Ensimm√§iset tarkastukset ja valvontatoimet.

### K√§yt√§nn√∂n vaikutukset organisaatioille

- Palveluiden riskiluokittelu ja hallittavuus.  
- Velvoite osoittaa, ett√§ j√§rjestelm√§ on valvottavissa ja hallittavissa.  
- Palveluntarjoajien (konsultit, MSP:t, SaaS-toimijat) vastuut kasvavat.

### Suurimmat kitkakohdat

- Rajapintakeskustelu: mik√§ on ‚Äúkorkean riskin‚Äù agentti.  
- Vastuunjako: kuka on provider, kuka deployer.  
- Shadow AI -tapaukset, joita ei voida poistaa.

---

## üî∂ 3. Shadow AI: miksi siit√§ ei p√§√§st√§ eroon?

Shadow AI ei katoa, koska:

- ty√∂ntekij√§t haluavat nopeutta, eiv√§t byrokratiaa  
- ty√∂ntekij√§t k√§ytt√§v√§t omia agenttejaan (selaimen laajennukset, mobiiliassistentit)  
- konsultit ja palveluntarjoajat tuovat omia ty√∂kalujaan asiakkaan ymp√§rist√∂√∂n  
- organisaation sis√§ll√§ voi olla rajapintoja, joita kukaan ei hallitse  

### Uutta 2026‚Äì2027

Shadow AI siirtyy yksitt√§isist√§ kyselyist√§ automaattisiin agentteihin, jotka:

- tekev√§t p√§√§t√∂ksi√§  
- valvovat toisia agentteja  
- ohjaavat dokumentaatiota  

Riskitaso nousee, koska kyse ei ole en√§√§ yksitt√§isest√§ kokeilusta, vaan jatkuvasta, n√§kym√§tt√∂m√§st√§ prosessista.

---

## üî∂ 4. Haavoittuvuudet ja riskit: mit√§ on realistisesti odotettavissa?

### 1. Agenttien hallinnan pett√§minen

- Agentti tekee asioita, joita ei huomata ajoissa.  
- Logiikka ei ole dokumentoitu eik√§ testattu.  
- Agentti oppii v√§√§r√§n toimintamallin ja toistaa sit√§ automaattisesti.

### 2. Supply chain -riskit

- Konsultin tai palveluntarjoajan agentti k√§ytt√§√§ asiakkaan dataa ‚Üí data vuotaa.  
- Palveluntarjoajan agentti p√§ivittyy automaattisesti ‚Üí uusi versio muuttaa toimintaa.

### 3. Prompt injection 2.0

Ei en√§√§ pelkk√§√§ tekstin manipulointia ‚Äî agentti voidaan ohjata:

- tekem√§√§n API-kutsuja  
- muuttamaan asetuksia  
- poistamaan dataa  
- l√§hett√§m√§√§n viestej√§  

### 4. Hallitsematon integraatiokaaos

- Agentit kytkeytyv√§t toisiinsa ilman keskitetty√§ arkkitehtuuria.  
- Organisaatiot eiv√§t tied√§, mit√§ agentteja on k√§yt√∂ss√§.

### 5. Lains√§√§d√§nn√∂n ja k√§yt√§nn√∂n ristiriita

- EU AI Act edellytt√§√§ dokumentaatiota ja valvontaa.  
- Todellisuudessa agentit ovat dynaamisia, p√§ivittyvi√§ ja vaikeasti j√§ljitett√§vi√§.

---

## üî∂ 5. Mit√§ t√§m√§ tarkoittaa arkkitehdeille ja governance-rakentajille?

Organisaatiot tarvitsevat:

- arkkitehtuurin: mik√§ on sallittua, mik√§ ei  
- agenttien hallintamallin: oikeudet, valvonta, lokitus  
- roolien ja vastuiden jaon: ty√∂ntekij√§t, konsultit, palveluntarjoajat  
- Shadow AI -strategian: ei kieltoja, vaan hallittu malli  
- dokumentaatiomallin: agenttiketjut ja datavirrat  

Arkkitehdeill√§ ja politiikan rakentajilla on keskeinen rooli, koska organisaatiot eiv√§t viel√§ osaa rakentaa n√§it√§ itse.

---

## üî∂ 6. Realistinen skenaario 2026‚Äì2028

- Agentit ovat kaikkialla  
- EU AI Act pakottaa dokumentoimaan kaiken  
- Shadow AI kasvaa, ei katoa  
- Haavoittuvuudet monimutkaistuvat  
- Organisaatiot tarvitsevat uusia governance-malleja  
- Arkkitehdit ja politiikan rakentajat nousevat avainrooliin  
